--------------------Best Config--------------------
{'model_name': 'roberta', 'batch_size': 32, 'lr': 5e-05, 'num_epochs': 4, 'warmup_steps': 0}
Using custom data configuration default
Reusing dataset health_fact (/home/zh2095/.cache/huggingface/datasets/health_fact/default/1.1.0/99503637e4255bd805f84d57031c18fe4dd88298f00299d56c94fc59ed68ec19)
Loading cached processed dataset at /home/zh2095/.cache/huggingface/datasets/health_fact/default/1.1.0/99503637e4255bd805f84d57031c18fe4dd88298f00299d56c94fc59ed68ec19/cache-e2847b2b1fc0054c.arrow
Loading cached processed dataset at /home/zh2095/.cache/huggingface/datasets/health_fact/default/1.1.0/99503637e4255bd805f84d57031c18fe4dd88298f00299d56c94fc59ed68ec19/cache-d932402a6b2ca71e.arrow
The following columns in the test set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: explanation. If explanation are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Prediction *****
  Num examples = 1233
  Batch size = 8
  0%|          | 0/155 [00:00<?, ?it/s]  3%|▎         | 4/155 [00:00<00:04, 31.32it/s]  5%|▌         | 8/155 [00:00<00:05, 27.32it/s]  7%|▋         | 11/155 [00:00<00:05, 26.74it/s]  9%|▉         | 14/155 [00:00<00:05, 26.45it/s] 11%|█         | 17/155 [00:00<00:05, 26.30it/s] 13%|█▎        | 20/155 [00:00<00:05, 26.20it/s] 15%|█▍        | 23/155 [00:00<00:05, 26.13it/s] 17%|█▋        | 26/155 [00:00<00:04, 26.10it/s] 19%|█▊        | 29/155 [00:01<00:04, 26.08it/s] 21%|██        | 32/155 [00:01<00:04, 26.07it/s] 23%|██▎       | 35/155 [00:01<00:04, 26.01it/s] 25%|██▍       | 38/155 [00:01<00:04, 25.96it/s] 26%|██▋       | 41/155 [00:01<00:04, 25.98it/s] 28%|██▊       | 44/155 [00:01<00:04, 25.98it/s] 30%|███       | 47/155 [00:01<00:04, 26.00it/s] 32%|███▏      | 50/155 [00:01<00:04, 26.00it/s] 34%|███▍      | 53/155 [00:02<00:03, 26.00it/s] 36%|███▌      | 56/155 [00:02<00:03, 26.00it/s] 38%|███▊      | 59/155 [00:02<00:03, 26.00it/s] 40%|████      | 62/155 [00:02<00:03, 25.90it/s] 42%|████▏     | 65/155 [00:02<00:03, 25.81it/s] 44%|████▍     | 68/155 [00:02<00:03, 25.84it/s] 46%|████▌     | 71/155 [00:02<00:03, 25.91it/s] 48%|████▊     | 74/155 [00:02<00:03, 25.94it/s] 50%|████▉     | 77/155 [00:02<00:03, 25.84it/s] 52%|█████▏    | 80/155 [00:03<00:02, 25.89it/s] 54%|█████▎    | 83/155 [00:03<00:02, 25.94it/s] 55%|█████▌    | 86/155 [00:03<00:02, 25.98it/s] 57%|█████▋    | 89/155 [00:03<00:02, 25.95it/s] 59%|█████▉    | 92/155 [00:03<00:02, 25.94it/s] 61%|██████▏   | 95/155 [00:03<00:02, 25.96it/s] 63%|██████▎   | 98/155 [00:03<00:02, 25.90it/s] 65%|██████▌   | 101/155 [00:03<00:02, 25.81it/s] 67%|██████▋   | 104/155 [00:03<00:01, 25.77it/s] 69%|██████▉   | 107/155 [00:04<00:01, 25.76it/s] 71%|███████   | 110/155 [00:04<00:01, 25.76it/s] 73%|███████▎  | 113/155 [00:04<00:01, 25.74it/s] 75%|███████▍  | 116/155 [00:04<00:01, 25.69it/s] 77%|███████▋  | 119/155 [00:04<00:01, 25.68it/s] 79%|███████▊  | 122/155 [00:04<00:01, 25.66it/s] 81%|████████  | 125/155 [00:04<00:01, 25.67it/s] 83%|████████▎ | 128/155 [00:04<00:01, 25.68it/s] 85%|████████▍ | 131/155 [00:05<00:00, 25.68it/s] 86%|████████▋ | 134/155 [00:05<00:00, 25.68it/s] 88%|████████▊ | 137/155 [00:05<00:00, 25.70it/s] 90%|█████████ | 140/155 [00:05<00:00, 25.67it/s] 92%|█████████▏| 143/155 [00:05<00:00, 25.68it/s] 94%|█████████▍| 146/155 [00:05<00:00, 25.33it/s] 96%|█████████▌| 149/155 [00:05<00:00, 25.43it/s] 98%|█████████▊| 152/155 [00:05<00:00, 25.45it/s] 
-------------------- Measure for Model Efficiency --------------------
Number of samples predicted per second: 9.314016249539362
-------------------- Measure for Model Performance --------------------
weighted f1: {'f1': 0.7106768991460076}
micro f1: {'f1': 0.7137064071370642}
macro f1: {'f1': 0.6056580303706542}
100%|██████████| 155/155 [00:06<00:00, 24.00it/s]
